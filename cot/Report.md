# 基于Baseline的Few-shot CoT优化

## 一、实验背景

本实验聚焦于小学数学题自动求解任务，目标是基于baseline方案，通过引入Few-shot Chain-of-Thought（CoT）推理模式，提升大语言模型（Qwen2.5-0.5B-Instruct）的解题准确率。

---

## 二、Baseline方案简述

- **模型**：Qwen2.5-0.5B-Instruct
- **推理方式**：Zero-shot（仅用题目和指令，无推理示例）
- **答案提取**：直接从模型输出中提取数字
- **分数**：0.1385

Baseline方案下，模型经常只输出答案，导致准确率受限。

---

## 三、Few-shot CoT方案设计

### 1. Few-shot CoT原理

Few-shot CoT（Chain-of-Thought）即在prompt中加入带有详细推理步骤的示例，显式引导模型模仿推理链，提升其多步推理和复杂题目的解答能力。

### 2. 具体实现

- 在每个问题前，插入2个带有详细推理过程和答案的示例（如"计算 5 + 3 × 2"、"小明有10个苹果，吃了4个，还剩几个？"等），让模型学习如何分步推理并输出最终答案。
- 其余流程（批处理、进度条、答案提取等）与baseline保持一致。

---

## 四、实验结果对比

![1747925592510](image/Report/1747925592510.png)

| 方案         | 分数   |
| ------------ | ------ |
| Baseline     | 0.1385 |
| Few-shot CoT | 0.1505 |

- Few-shot CoT方案分数提升至0.1505，较baseline提升约8.7%。
